{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:pandas==1.3.5\n",
      "INFO:__main__:numpy==1.22.0\n",
      "INFO:__main__:scikit-learn==1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Check library versions\n",
    "logger.info(\"pandas==%s\", pandas.__version__)\n",
    "logger.info(\"numpy==%s\", numpy.__version__)\n",
    "logger.info(\"scikit-learn==%s\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:training_data.shape: (571, 12)\n",
      "INFO:__main__:Sample Trainning Data: \n",
      "    PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
      "0          145       2        Andrew, Mr. Edgardo Samuel    male  18.0      0   \n",
      "1          531       2          Quick, Miss. Phyllis May  female   2.0      1   \n",
      "2          387       3   Goodwin, Master. Sidney Leonard    male   1.0      5   \n",
      "3           94       3           Dean, Mr. Bertram Frank    male  26.0      1   \n",
      "4          753       3  Vande Velde, Mr. Johannes Joseph    male  33.0      0   \n",
      "\n",
      "   Parch     Ticket    Fare Cabin Embarked  Survived  \n",
      "0      0     231945  11.500   NaN        S         0  \n",
      "1      1      26360  26.000   NaN        S         1  \n",
      "2      2    CA 2144  46.900   NaN        S         0  \n",
      "3      2  C.A. 2315  20.575   NaN        S         0  \n",
      "4      0     345780   9.500   NaN        S         0  \n"
     ]
    }
   ],
   "source": [
    "# Loding Training Data\n",
    "training_data = pandas.read_csv(\"train.csv\")\n",
    "logger.info(\"training_data.shape: %s\", training_data.shape)\n",
    "logger.info(\"Sample Trainning Data: \\n %s\", training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining predictors and target variable\n",
    "numeric_predictors = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "categorical_predictors = [\"Sex\", \"Cabin\", \"Embarked\"]\n",
    "target_variable = \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering trainng data to predictors + target\n",
    "training_data = training_data[numeric_predictors+categorical_predictors+[target_variable]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Sex           0\n",
       "Cabin       426\n",
       "Embarked      2\n",
       "Survived      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null Values\n",
    "training_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Replacing Nulls\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Replacing Nulls\")\n",
    "training_data.replace(to_replace=[None], value=numpy.nan, inplace=True)\n",
    "training_data[numeric_predictors] = training_data.loc[:, numeric_predictors].apply(\n",
    "    pandas.to_numeric, errors=\"coerce\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting 'y_train' and 'X_train'\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setting 'y_train' and 'X_train'\")\n",
    "X_train = training_data.drop(\"Survived\", axis=1)\n",
    "y_train = training_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting up numeric transformer Pipeline\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setting up numeric transformer Pipeline\")\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setting up categorical transformer Pipeline\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Setting up categorical transformer Pipeline\")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing preprocessor\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Initializing preprocessor\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_predictors),\n",
    "        (\"cat\", categorical_transformer, categorical_predictors),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing model pipeline\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Initializing model pipeline\")\n",
    "model = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", RandomForestClassifier(random_state=42))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fitting model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Pclass', 'Age', 'SibSp',\n",
       "                                                   'Parch', 'Fare']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Sex', 'Cabin',\n",
       "                                                   'Embarked'])])),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"Fitting model\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Model fitting complete. Writing RFC_model.pkl\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Model fitting complete. Writing RFC_model.pkl\")\n",
    "with open(\"RFC_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Accuracy on training data 0.811189: \n"
     ]
    }
   ],
   "source": [
    "# Let's check Performance on test data\n",
    "test_data = pandas.read_csv(\"test.csv\")\n",
    "test_data = test_data[numeric_predictors+categorical_predictors+[target_variable]]\n",
    "\n",
    "test_accuracy = model.score(\n",
    "    test_data[numeric_predictors+categorical_predictors],test_data[\"Survived\"]\n",
    ")\n",
    "logger.info(\"Accuracy on training data %f: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's score New Data (no ground truth)\n",
    "new_data = pandas.read_csv(\"predict.csv\")\n",
    "new_scores = model.predict(new_data[numeric_predictors+categorical_predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "\n",
    "\n",
    "# modelop.init\n",
    "def begin():\n",
    "\n",
    "    global model\n",
    "    model = pickle.load(open(\"RFC_model.pkl\", \"rb\"))\n",
    "    logger.info(\"'RFC_model.pkl' file loaded to global variable 'model'\")\n",
    "\n",
    "    global numeric_predictors, categorical_predictors, target_variable\n",
    "    numeric_predictors = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "    categorical_predictors = [\"Sex\", \"Cabin\", \"Embarked\"]\n",
    "    target_variable = \"Survived\"\n",
    "    logger.info(\"Variable roles assigned\")\n",
    "\n",
    "\n",
    "# modelop.score\n",
    "def predict(scoring_data):\n",
    "\n",
    "    scoring_data=pandas.DataFrame([scoring_data])\n",
    "\n",
    "    scoring_data[\"Prediction\"] = model.predict(\n",
    "        scoring_data[numeric_predictors + categorical_predictors]\n",
    "    )\n",
    "    yield scoring_data.to_dict(orient=\"records\")[0]\n",
    "\n",
    "\n",
    "# modelop.metrics\n",
    "def metrics(metrics_df):\n",
    "\n",
    "    logger.info(\"metrics_df is of shape: %s\", metrics_df.shape)\n",
    "\n",
    "    X_test = metrics_df.drop(\"Survived\", axis=1)\n",
    "    y_true = metrics_df[\"Survived\"]\n",
    "    yield {\n",
    "        \"ACCURACY\": model.score(\n",
    "            X_test[numeric_predictors + categorical_predictors], y_true\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "# modelop.train\n",
    "def train(training_df):\n",
    "\n",
    "    logger.info(\"train_df is of shape: %s\", training_df.shape)\n",
    "\n",
    "    numeric_predictors = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "    categorical_predictors = [\"Sex\", \"Cabin\", \"Embarked\"]\n",
    "    target_variable = \"Survived\"\n",
    "\n",
    "    training_df = training_df.loc[\n",
    "        :, numeric_predictors + categorical_predictors + [target_variable]\n",
    "    ]\n",
    "\n",
    "    logger.info(\"Replacing Nulls\")\n",
    "    training_df.replace(to_replace=[None], value=numpy.nan, inplace=True)\n",
    "    training_df[numeric_predictors] = training_df.loc[:, numeric_predictors].apply(\n",
    "        pandas.to_numeric, errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"Setting 'y_train' and 'X_train'\")\n",
    "    X_train = training_df.drop(\"Survived\", axis=1)\n",
    "    y_train = training_df[\"Survived\"]\n",
    "\n",
    "    logger.info(\"Setting up numeric transformer Pipeline\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Setting up categorical transformer Pipeline\")\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Initializing preprocessor\")\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_predictors),\n",
    "            (\"cat\", categorical_transformer, categorical_predictors),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Initializing model pipeline\")\n",
    "    model = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", RandomForestClassifier(random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logger.info(\"Fitting model\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # pickle file should be written to outputDir/\n",
    "    logger.info(\"Model fitting complete. Writing 'RFC_model.pkl' to outputDir/\")\n",
    "    with open(\"outputDir/RFC_model.pkl\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    logger.info(\"Training Job Complete!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets to test functions\n",
    "predict_data = pandas.read_csv(\"predict.csv\")\n",
    "test_data = pandas.read_csv(\"test.csv\")\n",
    "training_data = pandas.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:'RFC_model.pkl' file loaded to global variable 'model'\n",
      "INFO:__main__:Variable roles assigned\n"
     ]
    }
   ],
   "source": [
    "begin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PassengerId': 871,\n",
       " 'Pclass': 3,\n",
       " 'Name': 'Balkic, Mr. Cerin',\n",
       " 'Sex': 'male',\n",
       " 'Age': 26.0,\n",
       " 'SibSp': 0,\n",
       " 'Parch': 0,\n",
       " 'Ticket': '349248',\n",
       " 'Fare': 7.8958,\n",
       " 'Cabin': nan,\n",
       " 'Embarked': 'S',\n",
       " 'Prediction': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(predict(predict_data.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:metrics_df is of shape: (143, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ACCURACY': 0.8111888111888111}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(metrics(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:train_df is of shape: (571, 12)\n",
      "INFO:__main__:Replacing Nulls\n",
      "INFO:__main__:Setting 'y_train' and 'X_train'\n",
      "INFO:__main__:Setting up numeric transformer Pipeline\n",
      "INFO:__main__:Setting up categorical transformer Pipeline\n",
      "INFO:__main__:Initializing preprocessor\n",
      "INFO:__main__:Initializing model pipeline\n",
      "INFO:__main__:Fitting model\n",
      "INFO:__main__:Model fitting complete. Writing 'RFC_model.pkl' to outputDir/\n",
      "INFO:__main__:Training Job Complete!\n"
     ]
    }
   ],
   "source": [
    "train(training_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bc0af681b6debbd76b10de7ba3014cd62e1e3ee55e8e9a892bbbe23fd8d618c"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('modelop': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
